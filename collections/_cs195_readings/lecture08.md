---
layout: cs195-reading
date: 2023-10-11
number: "08"
title: "[guest] Generative AI, Part I"
slides:
  link: "https://docs.google.com/presentation/d/1MYl2FFeMdgGXNz1bpDZXg0MkY81ClBcz8sXzQ0HmcLw/edit"
  released: false
readings_released: false
---

**Fill out [this survey][l08_form] by Monday 03/06 at 11:59 PM.**

* **Required**: Washington Post, ["A computer program used for bail and sentencing decisions was labeled biased against blacks. It's actually not that clear."](https://www.washingtonpost.com/news/monkey-cage/wp/2016/10/17/can-an-algorithm-be-racist-our-analysis-is-more-cautious-than-propublicas/#comments), 2016.
  * Copied to EdStem: https://edstem.org/us/courses/35154/discussion/2715737
* **Required**: The New York Times. ["Make Algorithms Accountable"](https://www.nytimes.com/2016/08/01/opinion/make-algorithms-accountable.html?_r=0), 2016.
* Recommended: Tufekci, Zeynep, ["Machine intelligence makes human morals more important"](https://www.ted.com/talks/zeynep_tufekci_machine_intelligence_makes_human_morals_more_important) (video)
* Optional: Google Research, ["Attacking discrimination with smarter machine learning"](https://research.google.com/bigpicture/attacking-discrimination-in-ml/)

[l08_form]: https://docs.google.com/forms/d/e/1FAIpQLSd0pfoFGJ8XHYAzc0QzpYWSq8yc6_dOI9Uyj_5fWP6SlbsJlw/viewform
